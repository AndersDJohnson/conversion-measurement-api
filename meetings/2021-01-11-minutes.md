# Conversion Measurement API

Jan 11, 2021

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)


# Agenda



*   Group goals
    *   E.g. experimental implementations, testing, usage feedback
*   OT reminder
    *   Getting started with OT - [barbesmith@google.com](mailto:barbesmith@google.com), darojas@google.com
    *   Change in M88 (John Delaney)
*   Cleaning up conversion registration ([issue 91](https://github.com/WICG/conversion-measurement-api/issues/91))
*   Possible mitigations to support event-level API view through conversions ([issue](https://github.com/WICG/conversion-measurement-api/issues/98))
    *   Privacy issues w/ VTC
    *   [Rate limiting](https://github.com/WICG/conversion-measurement-api/#reporting-cooldown), [LDP noise](https://github.com/WICG/conversion-measurement-api/issues/84), Pending advertiser caps.
*   Cross-domain conversions
*   Any other business


# Attendees — please sign yourself in!



1. Charlie Harrison (Google)
2. Ben Savage (Facebook)
3. Valentino Volonghi (NextRoll)
4. Barb Smith (Google)
5. Erik Taubeneck
6. Benjamin Case (Facebook)
7. Danny Rojas (Google)
8. John Dlenaye (Google)
9. Basile Leparmentier (Criteo)
10. Michael Kleber (Google Chrome)
11. Ryan Avecilla (Neustar)
12. Joao Natali (Neustar)
13. Brad Lassey (Google Chrome)
14. Przemyslaw Iwanczak (RTB House)
15. Andrew Pascoe (NextRoll)
16. Marshall Vale (Google)
17. Andrew Knox (Facebook)
18. Matt Zambelli (Neustar)


# Notes



*   Scribe: Michael Kleber


## Group goals

 *   E.g. experimental implementations, testing, usage feedback

Erik Taubeneck: Seems like there are three types of questions we're discussing: 



1. What data gets stored?
2. What can be run on that data in the browser?
3. What can be run in the aggregate-API/MPC domain to get information out of the browser?

What are our goals for each of these three things this year?

Charlie H: We should definitely have experimental code running; in Chrome we already have the simplest version up and running (next agenda item).  We should work on iterating on all three of the domains Erik mentioned, with the end goal of satisfying all of the use cases by EOY.  We're working with a tough timeline, but that's reality.  Still iterating on design decisions now, but we can figure out v2 of the experiment, and get it out the door.

...Certainly want to hear new use cases, additional processing wishes, as long as they satisfy the privacy goals.

Basile L: We (Criteo) proposed a different mechanism, mostly for TURLTEDOVE and relying on k-anonymity, because we felt it would work substantially better for some use cases, and that Differential Privacy will have an extremely hard time supporting the optimization use cases.  If we want to make counter-proposals that compete with yours, how do we do this?  You have a great and ambitious objective for this year, but how do we think about proposals that are a quite different framework?

Charlie H: Differential Privacy vs optimization is a critical question.  In the conception of the original event-level API, we did cede some of the DP protections, in order to support the optimization use case.  In the existing proposal, for example, the unique ID on one side, which doesn't get noised, is all about allowing you to recover enough info to train some types of prediction models.  The relaxation of DP was something that at the very least makes it difficult to join up a user's identity across the publisher and advertiser site (e.g. 3-bits and a little noise).  The intention is that an attack could only transfer identity across sites if the user clicked a lot of times, would be hard to pull off in practice.

...If we're looking at something substantially different from DP, want similar characteristics: Look at worst-case attacks, how hard it is to recover worst-case privacy loss = linking identity across sites.  If we can find a way to do that which fits with the API, that works with the TURTLEDOVE / SPARROW use case, that should be fine.  I proposed something in an Issue a couple of months ago, that proposed the reverse of the event-level API, where the unique-ID is on the advertiser side and the low-bit info is from the publisher site.  Should have similar privacy properties to the existing API, but more like what you described in SPARROW.

...In principle we want to support the use case, but it's difficult.

Erik T: Might make sense for us to write up a threat model, could help the conversations.  Writing down in a bit more detail would help.

Basile L: Worst-case scenario is great to think about, but remember that you can always trick the user into typing in their email or something like that, who isn't aware about what they are giving away.  So worst-case scenario should instead be about whether there is a way to automate the attack at scale.  It's a cost-benefit analysis — not worst-case scenario, more about "is it a feasible attack that is not too expensive?"

…in SPARROW proposal we have k-anonymity, which is not perfect, but you still need to do a lot of work to get identity information out of it.  We can assume people won't do 10,000 ads or 5,000 clicks from the same person.  Worst-case-with-reasonable-cost-benefit-analysis.

Robert Stratton: I agree that measurement proposals take slightly different approaches on what constitutes privacy, but also different notions of their goals and use cases.  I think there would be benefit from trying to coalesce those.  Threat model is one part of it, functionality goals is another important part, and we're probably not yet all on the same page.

Charlie: I agree that we want something more related than "worst case" that takes costs into account.  As long as we can do something like that which is a reasonable analysis, that's fine.  But we can't assume that sites are trying to be good actors.  We need to assume bad actors will try to use the API.  "Challenging" in terms of cost, or in terms of being limited by user behavior, those are good metrics — it's hard to get the user to do more stuff, so it acts to promote privacy.  Lots of attacks are possible even with DP — it's not about getting something that is unbeatable, just choose the things that provide the most value and are hardest to leak sensitive information about the user.

Basile: Great.  Obviously if someone has 10M euros to spend to track one user, they will succeed.  Can't be worst-case.

Erik: Seems like we should write down the threat model, taking this cost factor into consideration.  Also, as Robert says, we should write down the use cases that we'd like to enable this year (in those three categories I mentioned).

Charlie: I agree.  Maybe an uber-issue on the repo that describes the use cases that we could hit by end-of-year, in v1.5 or v2.  We could work on that in the two weeks before the next meeting.  Sound reasonable?  (assorted yesses)

Andrew Knox: You're suggesting use cases first?  Or the threat model at the same time?

Charlie: Was talking about both.  W3C PING has a threat model doc that they are trying to work through, which I'd hope to build on / be inspired by / contribute to.

Brad Lassey: It would be a good basis for this, and we should contribute back if we find things we think aren't covered.

Ben Savage: I found the PING model too extreme — it mentioned things like "knowing what links a person clicked on on a first-party site" as a threat.  Not sure whether to take it seriously or whether it's just a bunch of extremists.

Brad: The goal of the PING privacy model is to lay out all of the privacy threats, some of which will not be disallowed, some of which will definitely be disallowed, and there will be a grey area where there will be mitigations, and different UAs can set their bar somewhere in the middle.  The specific thing you mentioned, Ben, is something identified as definitely _is_ allowed on the web platform.

Ben: So who added that?

Brad: E.g. Malware is outside the threat model for the web platform, it's just not one we're trying to combat.

Ben: I'm even more confused now.  Chrome _does_ try to fight malware

Brad: Chrome does not take malware into account when evaluating the security of proposed changes to the web.  We haven't made changes to prevent cookie theft via malware — if you've compromised the device, then you can do things that wouldn't be possible in the web security model.

Charlie: If this doc is confusing about what threats the browser _should_ protect against, then maybe it's something that should be clarified in the doc.  Different browsers could say what threats they are trying to prevent.  Then we could use those stances to help us develop features; right now there might be confusion about what we're trying to protect.

Robert: Might be confusion over the intent of the threatening actor — the old confidentiality / availability / integrity distinction.  

Basile: I agree that from my POV the PING model was a little wide.  Maybe we should restate exactly what Chrome really wants to prevent.  Cross site tracking, also something about revealing the interests of the user.  Would be good to restate: I am Chrome, I have my POV about privacy, this is my threat, etc.  I would add what constitutes a privacy violation, that the advertiser knew where the user came from, and so on.  Once we agree (or agree to disagree!), would help everybody.

Ben: I believe that document exists, it's Chrome's proposed privacy model for the web.

Basile: Yes, but there is also on TURTLEDOVE some threats about wanting the publisher to not be able to learn the user's interest group, which surprised us and we needed to change our first proposal as a result.

Charlie: We could do some work to come up with a clean version of the model.  Some of what that first document was missing is captured by the PING model, e.g. sensitive information transmission without identity transmission.  There is some work that we can do to refine what we mean here.  There is value in going to the PING doc and figuring out what we're trying to protect against

Kleber: That original document that Ben referred to referred to the original proposals Chrome came out with. We have moved on. Privacy models can change over time as we realize things we want to protect change. It is not an endpoint. PIGIN failed on “sensitive information disclosure” even without revealing user IDs, so we adjusted the threat model as we learned more.

AIs:



*   MVP use cases
*   Better doc describing the threats


## OT (Origin Trial) reminder



*   Getting started with OT - [barbesmith@google.com](mailto:barbesmith@google.com), darojas@google.com
*   Change in M88 (John Delaney)

Barb Smith, Danny Rojas: We're on the web platform partnerships team, we want to get engagement and feedback on experimental features.  We have a current version of the API in origin trial, would be delighted to see more testing of the API in its current state — e.g. compare accuracy of the API vs. cookie-based measurement (for expected functionality), anything you can report on what you observe that we can share with the community.  We have some people trying it out, would like more.

...If you're interested in learning more about Origin Trial experimentation as a mechanism, please get in touch, we will work with you.

Ben Savage: From FB's perspective, this is very low priority, because only covers web-to-web, which is a very small percentage of FB revenue.  Most FB ads are native ads (within native apps), and from there we only have about 3 destinations: (1) FB, (2) app store, (3) web site = the largest one.  We really care about conversions fired from websites, but need support for ads inside native apps.

...This is not just FB, same is true for Instagram, Twitter, TikTok, many more.  Please pay attention to it.

Charlie: Guess that should go into that use case doc :-)

Basile: We want that too!

Barb: It's also good for us to hear from companies that are not interested in experimenting at this time and why not.  So thank you.

John Delaney: Change in the M88 Origin Trial: Previously only some percentage of users had the API enabled, thinking it would be hard for inconsistent diversion across sites.  We got feedback that people wanted to control diversion themselves.  So starting in M88 you're in control of diversion.  We'll be getting in touch with current participants to make clear what you need to change.


## Cleaning up conversion registration ([issue 91](https://github.com/WICG/conversion-measurement-api/issues/91))

_(Charlie: skipping in the interest of time — feel free to respond on Issue)_


## Possible mitigations to support view through conversions ([issue](https://github.com/WICG/conversion-measurement-api/issues/98))



*   Privacy issues w/ VTC
*   [Rate limiting](https://github.com/WICG/conversion-measurement-api/#reporting-cooldown), [LDP noise](https://github.com/WICG/conversion-measurement-api/issues/84), Pending advertiser caps.

Charlie: I opened the issue this morning.  Before this we only talked about view-through via the aggregate API.  We'd like to support view-through conversions in the event-level API, for utility reasons.  Issue is for brainstorming for how we can improve the privacy of the view-through use case to make it feasible, and what mitigations we're thinking about.

...Biggest reasons that views are more sensitive than clicks:



1. If we're slowly leaking information from advertiser site to publisher site, then in the click-through API these leaks are all gated on user clicks, which adds a big challenge in using the API to recover full 3p-cookie functionality — you'd need to get the user to click a lot.  View-through conversions don't have that barrier.  Aggregate explainer doesn't have any barrier to registering the equivalent of impressions, so much easier to abuse than click-through.
2. View-through API provides wholly new information: the user's browsing history.  In the click-through API, the publisher at the time knows a priori that the user is navigating to the destination site — this isn't a threat that it's possible to prevent in the browser.  In the view-through API, when you see a conversion report, you suddenly know that the user went on their own and navigated to this site — so you learn that a site is in the user's browsing history, which otherwise you couldn't have known.

...So want to explore possible mitigations to allow this API in the event-level regime.  Possible mitigations:



1. Noising — local differential privacy
2. Clamping down existing restrictions, e.g. rate-limiting how often the API can be used.  Limit the number of publisher-advertiser pairs that can exist on a given site, for example.  Slows down information leakage attacks.
3. Breadth-based rate limiting, rather than depth-based: limit the number of pending advertiser sites that one publisher could be targeting — don't want a publisher to log fake impressions for the whole Alexa 10,000, and then have a script that logs conversions any time a user navigates to a page, which would allow you to learn the set of all sites the user visits.  Limiting to a small number of possible destination sites helps with them.

...These three mitigations do a somewhat good job of protecting user's privacy.

Ben S: I am really skeptical that we can ever pull this off.  Either aggregate-only, or else you leak browsing history.  If the browser leaks my browsing history due to ads that I never saw, or knew that I saw, seems like it would need prior consent + fabulous transparency tools, so that I could curate or turn off.

Erik T: There's another business threat: Publishers incentivised to seed as many impressions as possible, to get credit for conversions they don't deserve.  This is a business threat, even aside from the privacy threat problems.

Charlie: This is an ad fraud problem — so if the advertiser has a way to be sure the impression is legitimate, it alleviates this issue, right?

Erik: Not sure that is even meaningful — how could the advertiser verify that a thing was even displayed?

Charlie: All the existing viewability-etc tools that exist today.

Erik: It's much harder than with the click — browser observes that clicks really happened, and there isn't a comparable know that the view happened in order to trigger the event binding logic.  Maybe in _aggregate_ you could verify that, but I'm skeptical on event level.

Charlie: Could you write this up in a little more depth?  Please comment on the issue.

Valentino V: I was a little surprised not to see your issue mention SPURFOWL.  Discussion about whether you would allow running functions from the DSP multiple times or only once.  We could also not have those functions provided by the DSP at all, but only by the browser, which would limit the amount of nonsense that a DSP could do

Charlie: Having an area where the "crown jewels" are — all the cross-site data is available — does put you into the worst-case scenario.

 \
Valentino: That makes sense, but I think there are limits that we could put in place to mitigate the worst-case threat.


## Any other business

Brad: Would it be useful to invite the Privacy Threat Model editor to come speak here, or to the web-advertising BG?

Erik: Good idea — this meeting probably better than the BG.
