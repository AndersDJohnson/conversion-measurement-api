# Conversion Measurement API

Jan 25, 2021

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)

Use Google meet “Raise hand” for queuing


# Agenda



*   Introductions
*   Jeffrey Yasskin (Google): Target privacy threat model ([link](https://w3cping.github.io/privacy-threat-model/))
    *   Which threats are we protecting against?
    *   General discussion on our desired threat model
*   Erik Taubeneck (FB): Call for feedback on goals ([Issue 100](https://github.com/WICG/conversion-measurement-api/issues/100))
*   Matt Zambelli (Neustar): Review/draft functional requirements across current measurement proposals
*   Any other business


# Attendees — please sign yourself in!



1. Erik Taubeneck (Facebook)
2. Charlie Harrison (Google)
3. Mikko Juola (NextRoll)
4. Sadie Wilhelm (NextRoll)
5. Larissa Licha (NextRoll)
6. Matt Zambelli (Neustar)
7. Michael Kleber (Chrome)
8. Jeffrey Yasskin (Chrome)
9. Benjamin Case (Facebook)
10. Andrew Knox (Facebook)
11. Marshall Vale (Chrome)
12. Andrew Pascoe (NextRoll)
13. Ben Savage (Facebook)
14. John Delaney (Chrome)
15. Basile Leparmentier (Criteo)
16. Paul Marcilhacy (Criteo)


# Notes



*   Scribe: Erik Taubeneck


### Introductions



*   Sadie Wilhelm from NextRoll, team that presented [SPURFOWL](https://github.com/AdRoll/privacy/blob/main/SPURFOWL.md)
*   Jeffrey Yasskin - Chrome team, started Privacy threat model
*   Matt Zambelli - Neustar, presented [PeLICAn](https://github.com/neustar/pelican)
*   Benjamin Case - FB, working on cryptography


### Threat Model

Charlie Harrison: Two threat models. One from PING, Jeffrey here to talk about that.

Jeffrey Yasskin: ([Link to doc](https://w3cping.github.io/privacy-threat-model/)) Started this about a year ago to align across browser vendors. Not complete, it’s a design for threat models that needs contributions to fill it in. Identifies high level threats which actual privacy researchers should be contributing to. Much of this is coming from the IETF’s privacy documents and other W3C privacy docs.

The next section is the actual threat model. Here I invented something new, which is trying to describe if someone has certain abilities, i.e. can convince someone to load an iFrame, run JS, read server logs, then what type of cross-site communication should they be able to do. Describes what constraints we want to create. For instance, if you can only load iFrames, it shouldn’t be possible to send user_ids. For instance, the question of if click tracking was a threat, and we can’t get rid of click tracking, and we can’t get rid of server logs, then we use these to understand the implications of those threats. A lot of this was about ephemeral fingerprinting, device APIs, where you could read/write user_ids. 

The remaining sections explain the attacker capabilities that are used in the threat model. Essential Web APIs explains core functionality which we can’t get rid of.

Ben Savage: Thanks, I had asked questions before. One recommendation is to split this into multiple documents. This is a rather audacious document. Given the parts that are already fleshed out, then the remaining piece is centered about 3rd party tracking. One suggestion is to focus a document just on this, and we might find more alignment across browsers on this. When we talk about a privacy threat model, we make a distinction between 1st party and 3rd party. It’s unclear to me if 1st party is in scope.

Jeffrey Yasskin: When two sites are working together, they are 3rd parties from each other. There is a lot of 1st party stuff which should be part of the privacy model for the web, but a lot of what is in here currently is about 3rd parties.

Ben: How much alignment is there here?

Jeffrey: I’m expecting this document to nail down where we disagree, in addition to where we agree.

Ben: If we split this into different document, we might find more alignment on certain topics.

Charlie: What are the next steps? Is document UA policy something you’re looking to do here.

Jeffrey: UA policy is an interesting choice of words. I do want to outline what UAs are doing. I want to use this document to drive eventual agreement. 

Charlie: Makes sense. One big difference between this and HTML spec. Since this is the target privacy threat model, this is where we want to be. That would probably be useful, I wonder if there is a way to structure this to make this easier to document. Are we thinking about having enum values for each values in the grid for each browser? I’m not sure what structure you are thinking about.

Jeffrey: For things where we disagree, we dont’ have a way to show that. It might be an icon, it might be a description in the dropdown.

Charlie: I’m impressed you got this to render. I have a related question: A lot of the doc is focused on “essential web APIs” but it’s not clear on how to use the doc to inform new API decisions. Can you explain how to use this productively.

Jeffrey: New APIs should avoid breaking the threat model. Certain changes could break the web. We want to hold it to this bar, or to explicitly lower the bar.



 : Two things discussed last week: 



1. is the threat model going to look at worst-case scenario?  Or does it distinguish anything based on cost of an attack?  ("this thing is impossible" vs "this thing isn't economically feasible")
2. We've done work on preventing fraud.  When a new API opens a door that allows a new kind of fraud, should we write that down somewhere related?  Maybe it's not quite the _privacy_ threat model, but it is a new risk.

Jeffrey: re 1: Existing threat models should make it impossible. Things on the left hand side are things you could pay a publisher to do (put JS on your site, get access to your server logs), so other things like this belong as capabilities. 

Jeffrey: re 2: This seems like a security model thing, but no one has actually written a security model for the web. I’m not planning to write that, but it feels important to write down..

Basile: I just wanted to add that the first issue, we feel that the thread model of single actors that people are willing to do bad things, if you want to pay someone you could hire a private detective. We tend to focus on the pure API without thinking about the likely outcome. In the PING isLoggedIn which doesn’t give access to storage unless a user is logged in. This will cause many more sites to get users to log in, which would actually enable more cross party tracking. There is very clear increase in sharing of PII. My point is that when we think around privacy, we should consider both the worst case as well as the likely effect. I’m not sure how this is done typically.

Jeffrey: I pasted a link to an ecosystems paper. I think we need a ecosystems effect section that thinks through these systematic effects. I’m not sure it’s a threat model component, but it should be thought through. 

Basile: I’m quite new to this type of approach, but I think we should take both the cost of how you accomplish a certain capability into the analysis of the threat.

Jeffrey: I think the point you’re getting at is that adding isLoggedIn kind of lowers the net cost of a bunch of these types of attacks. I’m not entirely sure how to fit it into the threat model document.

Charlie: Threat model lists the goals of the attacker, if you can show that the goals can be met without compromising the privacy of the user, than you can assume the attacker will take the path that doesn’t violate the user’s privacy. I do think of looking at this from the perspective of the goals is important.

Jeffrey: There is the attacker's goals, and there's the actual purpose.

Basile: I want to agree with Charlie’s comment. Like you said no one wants the actual user_id, they want to use it to show advertising. If you propose something that is very hard to use, and it makes it economical then the ecosystem will shift to that API. If something is slightly worse in terms of privacy, but much better in terms of economic value, it might be better in aggregate. 

Erik: The current construction for Privacy Click Measurement would let you track up to 63 individuals, since you can use the buckets for size 1 for a few people.  So there is some analysis that says that in the worst-case scenario the Differential Privacy epsilon is infinity, but it's clearly less bad than something else

Jeffrey: You're right, that's not captured here, and something like it probably should be.

Ben: You'd like to capture cost through the rows of this table.  Seems like one cost is "you're willing to sacrifice some functionality elsewhere".  The PCM example looks like this — you're probably not willing to sacrifice all the rest of measurement to track these 64 people.  Similarly a publisher probably isn't willing to register a billion different TLDs.

Jeffrey: Nothing magic about this table. If people have other ideas, let me know.

Ben: Other question: How does one engage in a debate on this? This document looks really official? If I disagree that knowing someone clicked on a link on your side, where do I raise it?

Jeffrey: Will invite people to file issues in the [github repo](https://github.com/w3cping/privacy-threat-model/issues/) at the top of the document.


### Call for feedback on goals ([Issue 100](https://github.com/WICG/conversion-measurement-api/issues/100))

Erik: Posted issue 100 on goals. Just a proposal, trying to gather things heard here. Isn’t meant to be the list of goals. Seeding some ideas to help the conversation. Apologize it took 2 weeks to put it up.

Would love feedback. One big thing is the question on structure. Organizing by functionality then use-cases within. Or just use-cases at the top. Related q: if we want to think about generic functionality rather than use-case specific

E.g. proposal SPURFOWL which is a generic way of approaching write-only dataspace. Do we want to approach that as a generic thing or specific APIs

Do we want to coordinate w/ TURTLEDOVE work since that has write-only capabilities

Privacy implications of generic functionality is a lot harder to wrap heads around. Might make sense to do specific ones first then generalize. Happy to chat more about this.

Charlie: How would you like this issue to work over time?  Want this issue to reflect the goals of the group, with the top comment updating over time to reflect consensus?

Erik: Checkmarks → track if we’ve completed the goal. CTC impressions are checked. Should it be issue or markdown file. Just want it tracked somewhere where the progress is.

Michael: Checkmarks are not the right way to store state. Different for anybody. I see only my local state. 

Erik: We should not use checkmarks

Charlie: I'm happy that you wrote up this list — it's good documenting use cases that we agree are in/out of scope.  I'm not sure whether we should have SPURFOWL-style generic proposals in-scope for this group.  I think the idea has merits, but right now this group is scoped to conversion measurement while SPURFOWL is scoped to lots of different things.  Interested in hearing opinions.

Erik: Initial thoughts. Without something that can track a view in the browser. Adding “view” attributes becomes a generic write-only data storage. Can fire a view whenever you want. Maybe worth explicitly creating it so you can prperly

Charlie: It doesn't feel like a re-imagination of the dedicated conversion API, which is only about matching events on site A with site B (where site B is known at site A event time).  The default of a generic reporting API with shared write-only storage is very different from something whose privacy scope is limited to data leakage between two sites.  My concern with SPURFOWL in general is this difficulty of understanding the privacy scope – would be great if we could figure out how to impose limits on it that made its privacy threat similar to the conversion APIs, but that would be novel hard work.

Erik: Good questions, and definitely the sorts of things we'd need to discuss.

Ben: Two more goals, slightly out of the line of what we usually talk about in W3C.



1. Not limiting to web-only — any interest in tacking app-to-web? \
Charlie: Yes, I'm interested in this
2. Engagement with policy — stakeholders including regulators.  The value, usability, and success of the APIs are deeply intertwined with the comfort that regulators have with them.  Can we invite them in, get their feedback on what they are comfortable with? \
Charlie: I'm not as sure of that as a goal.  Nervous of painting us into a corner if we try to fit APIs into a global legal framework.  If we try to put the user's privacy first, that's a good first step.

Ben: If they don't fit into the global privacy framework, you have a problem

Basile: I agree with Ben — likely to have huge impact, not because APIs aren't private enough but because they are not used.  Bringing regulators with us does impose some constraints, but it's very important.

Erik: Q to Ben and Basile: Seems impractical to get policy involved to the extent that they would rubber-stamp an outcome or an API.  But there is value of talking with regulators about how this works, since we understand it and would be in a good position to teach them.  Not sure it's this group, but someone should be able to invite regulators in, show them how the sausage is made.

Ben: I would have phrased it differently, e.g. lets try to explain the high-level use cases that we're trying to achieve, get their takes on the intersection of technology and use cases — more forward-looking than how it's currently done

Basile: It's quite hard to get regulators to agree on anything.  If we do this, it's really going to affect the effectiveness of the effort.  Need to figure out how needs of DPAs etc. can be introduced into the conversation.  I don't know the best way to influence the regulators, but would be good to have some way to explain why this is privacy-safe, could be good for outcomes.  Could have high cost — not easy to have regulators chiming in on technical things — but has high Return On Investment too.

Charlie: Feels premature to be completely reactive, to design in isolation and just try to check off the boxes imposed by regulators, so maybe would be good if we could discuss APIs with them interactively.


### Matt Zambelli (Neustar): Review/draft functional requirements across current measurement proposals

Matt: Among the existing proposals, we took a stab at writing down the minimum requirements to support those functionalities. The idea here is not that this is definitive, but to start a unified proposal so that all needs are met. (Will post document to a publicly shared location in the coming days.)

Basile: I think it’s useful to have this type of document. 

Charlie: I can’t help but notice that the Conversion Measurement API which is the purpose of this call isn’t included. 

Matt: This is just the bird name proposals.

Charlie: I should have used a bird name. Seems like a useful reference.

Erik: Do we have a venue to unify among proposals.

Micheal: Seems like web-adv is good for over arching discussion. This group is operating under the auspices of the WICG, which is for specific proposals which are in incubation. 

Robert Stratton: It feels like if we are just doing things in this meeting, there are only 24 meetings this year. Is there any merit in putting together a unified proposal, is it any better than 6 different disparate proposals?

Charlie: I think a unified proposal would be easier to reason about, but would be difficult to accomplish. If it can be done, I think it would be valuable.
